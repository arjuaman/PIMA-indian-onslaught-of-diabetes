{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   6  148  72  35    0  33.6  0.627  50  1\n",
       "0  1   85  66  29    0  26.6  0.351  31  0\n",
       "1  8  183  64   0    0  23.3  0.672  32  1\n",
       "2  1   89  66  23   94  28.1  0.167  21  0\n",
       "3  0  137  40  35  168  43.1  2.288  33  1\n",
       "4  5  116  74   0    0  25.6  0.201  30  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset = loadtxt('pima-indians-diabetes-data.csv',delimiter=',')\n",
    "df=pd.read_csv('pima-indians-diabetes-data.csv',sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>plasma_glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>triceps_skin_fold_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diabetes_pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   times_pregnant  plasma_glucose_conc  diastolic_bp  \\\n",
       "0               1                   85            66   \n",
       "1               8                  183            64   \n",
       "2               1                   89            66   \n",
       "3               0                  137            40   \n",
       "4               5                  116            74   \n",
       "\n",
       "   triceps_skin_fold_thickness  insulin   bmi  diabetes_pedigree_function  \\\n",
       "0                           29        0  26.6                       0.351   \n",
       "1                            0        0  23.3                       0.672   \n",
       "2                           23       94  28.1                       0.167   \n",
       "3                           35      168  43.1                       2.288   \n",
       "4                            0        0  25.6                       0.201   \n",
       "\n",
       "   age  target  \n",
       "0   31       0  \n",
       "1   32       1  \n",
       "2   21       0  \n",
       "3   33       1  \n",
       "4   30       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers=['times_pregnant','plasma_glucose_conc','diastolic_bp',\n",
    "        'triceps_skin_fold_thickness','insulin','bmi',\n",
    "        'diabetes_pedigree_function','age','target']\n",
    "df.columns=headers\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "times_pregnant                 0\n",
       "plasma_glucose_conc            0\n",
       "diastolic_bp                   0\n",
       "triceps_skin_fold_thickness    0\n",
       "insulin                        0\n",
       "bmi                            0\n",
       "diabetes_pedigree_function     0\n",
       "age                            0\n",
       "target                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(df[['times_pregnant','plasma_glucose_conc','diastolic_bp',\n",
    "        'triceps_skin_fold_thickness','insulin','bmi',\n",
    "        'diabetes_pedigree_function','age']])\n",
    "y=np.asarray(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.84372629, -1.12208597, -0.16024856,  0.53202348, -0.69355921,\n",
       "        -0.68372895, -0.36426474, -0.18894038],\n",
       "       [ 1.23423997,  1.94447577, -0.26357823, -1.28688187, -0.69355921,\n",
       "        -1.10230105,  0.60470064, -0.1037951 ],\n",
       "       [-0.84372629, -0.99692019, -0.16024856,  0.15569823,  0.12235685,\n",
       "        -0.49346891, -0.91968415, -1.0403932 ],\n",
       "       [-1.14057861,  0.50506924, -1.50353429,  0.90834872,  0.76467376,\n",
       "         1.40913155,  5.48273197, -0.01864981],\n",
       "       [ 0.343683  , -0.15205113,  0.25307013, -1.28688187, -0.69355921,\n",
       "        -0.81056898, -0.8170523 , -0.27408566]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (460, 8) (460,)\n",
      "Test set: (307, 8) (307,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.4, random_state=42)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "460/460 [==============================] - 2s 5ms/step - loss: 0.6968 - accuracy: 0.5065\n",
      "Epoch 2/200\n",
      "460/460 [==============================] - 0s 301us/step - loss: 0.6738 - accuracy: 0.6500\n",
      "Epoch 3/200\n",
      "460/460 [==============================] - 0s 302us/step - loss: 0.6560 - accuracy: 0.7022\n",
      "Epoch 4/200\n",
      "460/460 [==============================] - 0s 322us/step - loss: 0.6380 - accuracy: 0.7130\n",
      "Epoch 5/200\n",
      "460/460 [==============================] - 0s 305us/step - loss: 0.6197 - accuracy: 0.7152\n",
      "Epoch 6/200\n",
      "460/460 [==============================] - 0s 299us/step - loss: 0.5990 - accuracy: 0.7370\n",
      "Epoch 7/200\n",
      "460/460 [==============================] - 0s 314us/step - loss: 0.5779 - accuracy: 0.7435\n",
      "Epoch 8/200\n",
      "460/460 [==============================] - 0s 316us/step - loss: 0.5554 - accuracy: 0.7413\n",
      "Epoch 9/200\n",
      "460/460 [==============================] - 0s 439us/step - loss: 0.5335 - accuracy: 0.7413\n",
      "Epoch 10/200\n",
      "460/460 [==============================] - 0s 288us/step - loss: 0.5158 - accuracy: 0.7326\n",
      "Epoch 11/200\n",
      "460/460 [==============================] - 0s 464us/step - loss: 0.5044 - accuracy: 0.7478\n",
      "Epoch 12/200\n",
      "460/460 [==============================] - 0s 522us/step - loss: 0.4938 - accuracy: 0.7587\n",
      "Epoch 13/200\n",
      "460/460 [==============================] - 0s 682us/step - loss: 0.4849 - accuracy: 0.7565\n",
      "Epoch 14/200\n",
      "460/460 [==============================] - 0s 572us/step - loss: 0.4773 - accuracy: 0.7609\n",
      "Epoch 15/200\n",
      "460/460 [==============================] - 0s 505us/step - loss: 0.4708 - accuracy: 0.7717\n",
      "Epoch 16/200\n",
      "460/460 [==============================] - 0s 512us/step - loss: 0.4655 - accuracy: 0.7696\n",
      "Epoch 17/200\n",
      "460/460 [==============================] - 0s 511us/step - loss: 0.4608 - accuracy: 0.7761\n",
      "Epoch 18/200\n",
      "460/460 [==============================] - 0s 653us/step - loss: 0.4572 - accuracy: 0.7696\n",
      "Epoch 19/200\n",
      "460/460 [==============================] - 0s 550us/step - loss: 0.4545 - accuracy: 0.7804\n",
      "Epoch 20/200\n",
      "460/460 [==============================] - 0s 529us/step - loss: 0.4500 - accuracy: 0.7783\n",
      "Epoch 21/200\n",
      "460/460 [==============================] - 0s 521us/step - loss: 0.4454 - accuracy: 0.7739\n",
      "Epoch 22/200\n",
      "460/460 [==============================] - 0s 533us/step - loss: 0.4427 - accuracy: 0.7696\n",
      "Epoch 23/200\n",
      "460/460 [==============================] - 0s 568us/step - loss: 0.4398 - accuracy: 0.7783\n",
      "Epoch 24/200\n",
      "460/460 [==============================] - 0s 557us/step - loss: 0.4377 - accuracy: 0.7739\n",
      "Epoch 25/200\n",
      "460/460 [==============================] - 0s 507us/step - loss: 0.4359 - accuracy: 0.7804\n",
      "Epoch 26/200\n",
      "460/460 [==============================] - 0s 450us/step - loss: 0.4338 - accuracy: 0.7804\n",
      "Epoch 27/200\n",
      "460/460 [==============================] - 0s 416us/step - loss: 0.4338 - accuracy: 0.7783\n",
      "Epoch 28/200\n",
      "460/460 [==============================] - 0s 375us/step - loss: 0.4303 - accuracy: 0.7826\n",
      "Epoch 29/200\n",
      "460/460 [==============================] - 0s 383us/step - loss: 0.4299 - accuracy: 0.7826\n",
      "Epoch 30/200\n",
      "460/460 [==============================] - 0s 496us/step - loss: 0.4264 - accuracy: 0.7848\n",
      "Epoch 31/200\n",
      "460/460 [==============================] - 0s 567us/step - loss: 0.4269 - accuracy: 0.7804\n",
      "Epoch 32/200\n",
      "460/460 [==============================] - 0s 457us/step - loss: 0.4222 - accuracy: 0.7826\n",
      "Epoch 33/200\n",
      "460/460 [==============================] - 0s 437us/step - loss: 0.4216 - accuracy: 0.7848\n",
      "Epoch 34/200\n",
      "460/460 [==============================] - 0s 451us/step - loss: 0.4193 - accuracy: 0.7891\n",
      "Epoch 35/200\n",
      "460/460 [==============================] - 0s 527us/step - loss: 0.4183 - accuracy: 0.7848\n",
      "Epoch 36/200\n",
      "460/460 [==============================] - 0s 568us/step - loss: 0.4151 - accuracy: 0.7913\n",
      "Epoch 37/200\n",
      "460/460 [==============================] - 0s 576us/step - loss: 0.4132 - accuracy: 0.8000\n",
      "Epoch 38/200\n",
      "460/460 [==============================] - 0s 514us/step - loss: 0.4141 - accuracy: 0.7978\n",
      "Epoch 39/200\n",
      "460/460 [==============================] - 0s 521us/step - loss: 0.4122 - accuracy: 0.7978\n",
      "Epoch 40/200\n",
      "460/460 [==============================] - 0s 576us/step - loss: 0.4108 - accuracy: 0.7978\n",
      "Epoch 41/200\n",
      "460/460 [==============================] - 0s 412us/step - loss: 0.4101 - accuracy: 0.7891\n",
      "Epoch 42/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.4027 - accuracy: 0.80 - 0s 504us/step - loss: 0.4078 - accuracy: 0.8000\n",
      "Epoch 43/200\n",
      "460/460 [==============================] - 0s 516us/step - loss: 0.4080 - accuracy: 0.8022\n",
      "Epoch 44/200\n",
      "460/460 [==============================] - 0s 513us/step - loss: 0.4075 - accuracy: 0.7978\n",
      "Epoch 45/200\n",
      "460/460 [==============================] - 0s 502us/step - loss: 0.4051 - accuracy: 0.7978\n",
      "Epoch 46/200\n",
      "460/460 [==============================] - 0s 482us/step - loss: 0.4048 - accuracy: 0.8000\n",
      "Epoch 47/200\n",
      "460/460 [==============================] - 0s 533us/step - loss: 0.4043 - accuracy: 0.8043\n",
      "Epoch 48/200\n",
      "460/460 [==============================] - 0s 433us/step - loss: 0.4022 - accuracy: 0.8087\n",
      "Epoch 49/200\n",
      "460/460 [==============================] - 0s 499us/step - loss: 0.4020 - accuracy: 0.8022\n",
      "Epoch 50/200\n",
      "460/460 [==============================] - 0s 512us/step - loss: 0.4001 - accuracy: 0.8087\n",
      "Epoch 51/200\n",
      "460/460 [==============================] - 0s 505us/step - loss: 0.3993 - accuracy: 0.8152\n",
      "Epoch 52/200\n",
      "460/460 [==============================] - 0s 517us/step - loss: 0.4001 - accuracy: 0.8109\n",
      "Epoch 53/200\n",
      "460/460 [==============================] - 0s 401us/step - loss: 0.3977 - accuracy: 0.8109\n",
      "Epoch 54/200\n",
      "460/460 [==============================] - 0s 579us/step - loss: 0.3951 - accuracy: 0.8152\n",
      "Epoch 55/200\n",
      "460/460 [==============================] - 0s 414us/step - loss: 0.3955 - accuracy: 0.8087\n",
      "Epoch 56/200\n",
      "460/460 [==============================] - 0s 461us/step - loss: 0.3950 - accuracy: 0.8109\n",
      "Epoch 57/200\n",
      "460/460 [==============================] - 0s 448us/step - loss: 0.3938 - accuracy: 0.8152\n",
      "Epoch 58/200\n",
      "460/460 [==============================] - 0s 497us/step - loss: 0.3909 - accuracy: 0.8196\n",
      "Epoch 59/200\n",
      "460/460 [==============================] - 0s 329us/step - loss: 0.3905 - accuracy: 0.8174\n",
      "Epoch 60/200\n",
      "460/460 [==============================] - 0s 317us/step - loss: 0.3897 - accuracy: 0.8217\n",
      "Epoch 61/200\n",
      "460/460 [==============================] - 0s 347us/step - loss: 0.3904 - accuracy: 0.8174\n",
      "Epoch 62/200\n",
      "460/460 [==============================] - 0s 448us/step - loss: 0.3872 - accuracy: 0.8283\n",
      "Epoch 63/200\n",
      "460/460 [==============================] - 0s 439us/step - loss: 0.3872 - accuracy: 0.8239\n",
      "Epoch 64/200\n",
      "460/460 [==============================] - 0s 401us/step - loss: 0.3865 - accuracy: 0.8174\n",
      "Epoch 65/200\n",
      "460/460 [==============================] - 0s 420us/step - loss: 0.3846 - accuracy: 0.8239\n",
      "Epoch 66/200\n",
      "460/460 [==============================] - 0s 355us/step - loss: 0.3859 - accuracy: 0.8217\n",
      "Epoch 67/200\n",
      "460/460 [==============================] - 0s 384us/step - loss: 0.3853 - accuracy: 0.8217\n",
      "Epoch 68/200\n",
      "460/460 [==============================] - 0s 409us/step - loss: 0.3822 - accuracy: 0.8326\n",
      "Epoch 69/200\n",
      "460/460 [==============================] - 0s 505us/step - loss: 0.3813 - accuracy: 0.8304\n",
      "Epoch 70/200\n",
      "460/460 [==============================] - 0s 570us/step - loss: 0.3808 - accuracy: 0.8261\n",
      "Epoch 71/200\n",
      "460/460 [==============================] - 0s 520us/step - loss: 0.3804 - accuracy: 0.8261\n",
      "Epoch 72/200\n",
      "460/460 [==============================] - 0s 387us/step - loss: 0.3809 - accuracy: 0.8283\n",
      "Epoch 73/200\n",
      "460/460 [==============================] - 0s 502us/step - loss: 0.3781 - accuracy: 0.8326\n",
      "Epoch 74/200\n",
      "460/460 [==============================] - 0s 496us/step - loss: 0.3784 - accuracy: 0.8283\n",
      "Epoch 75/200\n",
      "460/460 [==============================] - 0s 592us/step - loss: 0.3776 - accuracy: 0.8304\n",
      "Epoch 76/200\n",
      "460/460 [==============================] - 0s 555us/step - loss: 0.3764 - accuracy: 0.8283\n",
      "Epoch 77/200\n",
      "460/460 [==============================] - 0s 523us/step - loss: 0.3758 - accuracy: 0.8304\n",
      "Epoch 78/200\n",
      "460/460 [==============================] - 0s 508us/step - loss: 0.3761 - accuracy: 0.8261\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/460 [==============================] - 0s 433us/step - loss: 0.3732 - accuracy: 0.8326\n",
      "Epoch 80/200\n",
      "460/460 [==============================] - 0s 545us/step - loss: 0.3756 - accuracy: 0.8283\n",
      "Epoch 81/200\n",
      "460/460 [==============================] - 0s 543us/step - loss: 0.3758 - accuracy: 0.8304\n",
      "Epoch 82/200\n",
      "460/460 [==============================] - 0s 490us/step - loss: 0.3724 - accuracy: 0.8283\n",
      "Epoch 83/200\n",
      "460/460 [==============================] - 0s 503us/step - loss: 0.3720 - accuracy: 0.8304\n",
      "Epoch 84/200\n",
      "460/460 [==============================] - 0s 508us/step - loss: 0.3703 - accuracy: 0.8239\n",
      "Epoch 85/200\n",
      "460/460 [==============================] - 0s 510us/step - loss: 0.3697 - accuracy: 0.8304\n",
      "Epoch 86/200\n",
      "460/460 [==============================] - 0s 448us/step - loss: 0.3677 - accuracy: 0.8326\n",
      "Epoch 87/200\n",
      "460/460 [==============================] - 0s 452us/step - loss: 0.3681 - accuracy: 0.8304\n",
      "Epoch 88/200\n",
      "460/460 [==============================] - 0s 524us/step - loss: 0.3659 - accuracy: 0.8283\n",
      "Epoch 89/200\n",
      "460/460 [==============================] - 0s 505us/step - loss: 0.3662 - accuracy: 0.8348\n",
      "Epoch 90/200\n",
      "460/460 [==============================] - 0s 451us/step - loss: 0.3649 - accuracy: 0.8348\n",
      "Epoch 91/200\n",
      "460/460 [==============================] - 0s 324us/step - loss: 0.3643 - accuracy: 0.8413\n",
      "Epoch 92/200\n",
      "460/460 [==============================] - 0s 325us/step - loss: 0.3643 - accuracy: 0.8326\n",
      "Epoch 93/200\n",
      "460/460 [==============================] - 0s 337us/step - loss: 0.3631 - accuracy: 0.8283\n",
      "Epoch 94/200\n",
      "460/460 [==============================] - 0s 321us/step - loss: 0.3618 - accuracy: 0.8326\n",
      "Epoch 95/200\n",
      "460/460 [==============================] - 0s 305us/step - loss: 0.3613 - accuracy: 0.8391\n",
      "Epoch 96/200\n",
      "460/460 [==============================] - 0s 299us/step - loss: 0.3610 - accuracy: 0.8304\n",
      "Epoch 97/200\n",
      "460/460 [==============================] - 0s 322us/step - loss: 0.3585 - accuracy: 0.8370\n",
      "Epoch 98/200\n",
      "460/460 [==============================] - 0s 318us/step - loss: 0.3569 - accuracy: 0.8435\n",
      "Epoch 99/200\n",
      "460/460 [==============================] - 0s 316us/step - loss: 0.3591 - accuracy: 0.8348\n",
      "Epoch 100/200\n",
      "460/460 [==============================] - 0s 332us/step - loss: 0.3554 - accuracy: 0.8413\n",
      "Epoch 101/200\n",
      "460/460 [==============================] - 0s 323us/step - loss: 0.3554 - accuracy: 0.8326\n",
      "Epoch 102/200\n",
      "460/460 [==============================] - 0s 299us/step - loss: 0.3544 - accuracy: 0.8413\n",
      "Epoch 103/200\n",
      "460/460 [==============================] - 0s 349us/step - loss: 0.3534 - accuracy: 0.8370\n",
      "Epoch 104/200\n",
      "460/460 [==============================] - 0s 338us/step - loss: 0.3531 - accuracy: 0.8435\n",
      "Epoch 105/200\n",
      "460/460 [==============================] - 0s 340us/step - loss: 0.3535 - accuracy: 0.8370\n",
      "Epoch 106/200\n",
      "460/460 [==============================] - 0s 389us/step - loss: 0.3504 - accuracy: 0.8457\n",
      "Epoch 107/200\n",
      "460/460 [==============================] - 0s 364us/step - loss: 0.3498 - accuracy: 0.8391\n",
      "Epoch 108/200\n",
      "460/460 [==============================] - 0s 332us/step - loss: 0.3492 - accuracy: 0.8348\n",
      "Epoch 109/200\n",
      "460/460 [==============================] - 0s 356us/step - loss: 0.3475 - accuracy: 0.8435\n",
      "Epoch 110/200\n",
      "460/460 [==============================] - 0s 530us/step - loss: 0.3469 - accuracy: 0.8522\n",
      "Epoch 111/200\n",
      "460/460 [==============================] - 0s 543us/step - loss: 0.3460 - accuracy: 0.8500\n",
      "Epoch 112/200\n",
      "460/460 [==============================] - 0s 389us/step - loss: 0.3458 - accuracy: 0.8500\n",
      "Epoch 113/200\n",
      "460/460 [==============================] - 0s 379us/step - loss: 0.3447 - accuracy: 0.8478\n",
      "Epoch 114/200\n",
      "460/460 [==============================] - 0s 364us/step - loss: 0.3427 - accuracy: 0.84780s - loss: 0.3299 - accuracy: 0.\n",
      "Epoch 115/200\n",
      "460/460 [==============================] - 0s 530us/step - loss: 0.3432 - accuracy: 0.8543\n",
      "Epoch 116/200\n",
      "460/460 [==============================] - 0s 496us/step - loss: 0.3414 - accuracy: 0.8435\n",
      "Epoch 117/200\n",
      "460/460 [==============================] - 0s 401us/step - loss: 0.3407 - accuracy: 0.8522\n",
      "Epoch 118/200\n",
      "460/460 [==============================] - 0s 371us/step - loss: 0.3390 - accuracy: 0.8478\n",
      "Epoch 119/200\n",
      "460/460 [==============================] - 0s 341us/step - loss: 0.3386 - accuracy: 0.8565\n",
      "Epoch 120/200\n",
      "460/460 [==============================] - 0s 506us/step - loss: 0.3403 - accuracy: 0.8500\n",
      "Epoch 121/200\n",
      "460/460 [==============================] - 0s 518us/step - loss: 0.3356 - accuracy: 0.8587\n",
      "Epoch 122/200\n",
      "460/460 [==============================] - 0s 389us/step - loss: 0.3361 - accuracy: 0.8522\n",
      "Epoch 123/200\n",
      "460/460 [==============================] - 0s 537us/step - loss: 0.3346 - accuracy: 0.8630\n",
      "Epoch 124/200\n",
      "460/460 [==============================] - 0s 504us/step - loss: 0.3330 - accuracy: 0.8630\n",
      "Epoch 125/200\n",
      "460/460 [==============================] - 0s 520us/step - loss: 0.3333 - accuracy: 0.8500\n",
      "Epoch 126/200\n",
      "460/460 [==============================] - 0s 554us/step - loss: 0.3317 - accuracy: 0.8630\n",
      "Epoch 127/200\n",
      "460/460 [==============================] - 0s 496us/step - loss: 0.3311 - accuracy: 0.8696\n",
      "Epoch 128/200\n",
      "460/460 [==============================] - 0s 531us/step - loss: 0.3299 - accuracy: 0.8717\n",
      "Epoch 129/200\n",
      "460/460 [==============================] - 0s 519us/step - loss: 0.3315 - accuracy: 0.8674\n",
      "Epoch 130/200\n",
      "460/460 [==============================] - 0s 435us/step - loss: 0.3287 - accuracy: 0.8630\n",
      "Epoch 131/200\n",
      "460/460 [==============================] - 0s 341us/step - loss: 0.3278 - accuracy: 0.8609\n",
      "Epoch 132/200\n",
      "460/460 [==============================] - 0s 324us/step - loss: 0.3266 - accuracy: 0.8717\n",
      "Epoch 133/200\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.3252 - accuracy: 0.8739\n",
      "Epoch 134/200\n",
      "460/460 [==============================] - 0s 303us/step - loss: 0.3260 - accuracy: 0.8674\n",
      "Epoch 135/200\n",
      "460/460 [==============================] - 0s 357us/step - loss: 0.3248 - accuracy: 0.8630\n",
      "Epoch 136/200\n",
      "460/460 [==============================] - 0s 345us/step - loss: 0.3236 - accuracy: 0.8674\n",
      "Epoch 137/200\n",
      "460/460 [==============================] - 0s 341us/step - loss: 0.3250 - accuracy: 0.8609\n",
      "Epoch 138/200\n",
      "460/460 [==============================] - 0s 321us/step - loss: 0.3208 - accuracy: 0.8739\n",
      "Epoch 139/200\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.3205 - accuracy: 0.8674\n",
      "Epoch 140/200\n",
      "460/460 [==============================] - 0s 324us/step - loss: 0.3201 - accuracy: 0.8652\n",
      "Epoch 141/200\n",
      "460/460 [==============================] - 0s 345us/step - loss: 0.3199 - accuracy: 0.8674\n",
      "Epoch 142/200\n",
      "460/460 [==============================] - 0s 328us/step - loss: 0.3177 - accuracy: 0.8717\n",
      "Epoch 143/200\n",
      "460/460 [==============================] - 0s 328us/step - loss: 0.3166 - accuracy: 0.8587\n",
      "Epoch 144/200\n",
      "460/460 [==============================] - 0s 297us/step - loss: 0.3170 - accuracy: 0.8696\n",
      "Epoch 145/200\n",
      "460/460 [==============================] - 0s 312us/step - loss: 0.3157 - accuracy: 0.8696\n",
      "Epoch 146/200\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.3143 - accuracy: 0.8761\n",
      "Epoch 147/200\n",
      "460/460 [==============================] - 0s 296us/step - loss: 0.3124 - accuracy: 0.8674\n",
      "Epoch 148/200\n",
      "460/460 [==============================] - 0s 324us/step - loss: 0.3132 - accuracy: 0.8696\n",
      "Epoch 149/200\n",
      "460/460 [==============================] - 0s 312us/step - loss: 0.3115 - accuracy: 0.8717\n",
      "Epoch 150/200\n",
      "460/460 [==============================] - 0s 315us/step - loss: 0.3105 - accuracy: 0.8717\n",
      "Epoch 151/200\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.3089 - accuracy: 0.8739\n",
      "Epoch 152/200\n",
      "460/460 [==============================] - 0s 311us/step - loss: 0.3096 - accuracy: 0.8696\n",
      "Epoch 153/200\n",
      "460/460 [==============================] - 0s 314us/step - loss: 0.3084 - accuracy: 0.8717\n",
      "Epoch 154/200\n",
      "460/460 [==============================] - 0s 314us/step - loss: 0.3082 - accuracy: 0.8696\n",
      "Epoch 155/200\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.3056 - accuracy: 0.8717\n",
      "Epoch 156/200\n",
      "460/460 [==============================] - 0s 331us/step - loss: 0.3050 - accuracy: 0.8696\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/460 [==============================] - 0s 324us/step - loss: 0.3030 - accuracy: 0.8739\n",
      "Epoch 158/200\n",
      "460/460 [==============================] - 0s 299us/step - loss: 0.3052 - accuracy: 0.8696\n",
      "Epoch 159/200\n",
      "460/460 [==============================] - 0s 292us/step - loss: 0.3021 - accuracy: 0.8761\n",
      "Epoch 160/200\n",
      "460/460 [==============================] - 0s 302us/step - loss: 0.3004 - accuracy: 0.8674\n",
      "Epoch 161/200\n",
      "460/460 [==============================] - 0s 343us/step - loss: 0.3030 - accuracy: 0.8717\n",
      "Epoch 162/200\n",
      "460/460 [==============================] - 0s 371us/step - loss: 0.2991 - accuracy: 0.8739\n",
      "Epoch 163/200\n",
      "460/460 [==============================] - 0s 412us/step - loss: 0.2988 - accuracy: 0.8739\n",
      "Epoch 164/200\n",
      "460/460 [==============================] - 0s 453us/step - loss: 0.2964 - accuracy: 0.8739\n",
      "Epoch 165/200\n",
      "460/460 [==============================] - 0s 506us/step - loss: 0.2955 - accuracy: 0.8761\n",
      "Epoch 166/200\n",
      "460/460 [==============================] - 0s 505us/step - loss: 0.2943 - accuracy: 0.8739\n",
      "Epoch 167/200\n",
      "460/460 [==============================] - 0s 545us/step - loss: 0.2940 - accuracy: 0.8804\n",
      "Epoch 168/200\n",
      "460/460 [==============================] - 0s 508us/step - loss: 0.2933 - accuracy: 0.8696\n",
      "Epoch 169/200\n",
      "460/460 [==============================] - 0s 501us/step - loss: 0.2911 - accuracy: 0.8783\n",
      "Epoch 170/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.3003 - accuracy: 0.87 - 0s 501us/step - loss: 0.2883 - accuracy: 0.8804\n",
      "Epoch 171/200\n",
      "460/460 [==============================] - 0s 521us/step - loss: 0.2880 - accuracy: 0.8761\n",
      "Epoch 172/200\n",
      "460/460 [==============================] - 0s 489us/step - loss: 0.2868 - accuracy: 0.8761\n",
      "Epoch 173/200\n",
      "460/460 [==============================] - 0s 521us/step - loss: 0.2853 - accuracy: 0.8783\n",
      "Epoch 174/200\n",
      "460/460 [==============================] - 0s 507us/step - loss: 0.2845 - accuracy: 0.8783\n",
      "Epoch 175/200\n",
      "460/460 [==============================] - 0s 517us/step - loss: 0.2859 - accuracy: 0.8761\n",
      "Epoch 176/200\n",
      "460/460 [==============================] - 0s 514us/step - loss: 0.2834 - accuracy: 0.8717\n",
      "Epoch 177/200\n",
      "460/460 [==============================] - 0s 601us/step - loss: 0.2845 - accuracy: 0.8826\n",
      "Epoch 178/200\n",
      "460/460 [==============================] - 0s 631us/step - loss: 0.2799 - accuracy: 0.8848\n",
      "Epoch 179/200\n",
      "460/460 [==============================] - 0s 604us/step - loss: 0.2783 - accuracy: 0.8761\n",
      "Epoch 180/200\n",
      "460/460 [==============================] - 0s 474us/step - loss: 0.2797 - accuracy: 0.8826\n",
      "Epoch 181/200\n",
      "460/460 [==============================] - 0s 526us/step - loss: 0.2787 - accuracy: 0.8870\n",
      "Epoch 182/200\n",
      "460/460 [==============================] - 0s 550us/step - loss: 0.2762 - accuracy: 0.8826\n",
      "Epoch 183/200\n",
      "460/460 [==============================] - 0s 536us/step - loss: 0.2750 - accuracy: 0.8848\n",
      "Epoch 184/200\n",
      "460/460 [==============================] - 0s 454us/step - loss: 0.2738 - accuracy: 0.8826\n",
      "Epoch 185/200\n",
      "460/460 [==============================] - 0s 559us/step - loss: 0.2714 - accuracy: 0.8978\n",
      "Epoch 186/200\n",
      "460/460 [==============================] - 0s 491us/step - loss: 0.2696 - accuracy: 0.8804\n",
      "Epoch 187/200\n",
      "460/460 [==============================] - 0s 539us/step - loss: 0.2706 - accuracy: 0.8848\n",
      "Epoch 188/200\n",
      "460/460 [==============================] - 0s 446us/step - loss: 0.2688 - accuracy: 0.8848\n",
      "Epoch 189/200\n",
      "460/460 [==============================] - 0s 532us/step - loss: 0.2661 - accuracy: 0.8935\n",
      "Epoch 190/200\n",
      "460/460 [==============================] - 0s 568us/step - loss: 0.2644 - accuracy: 0.8913\n",
      "Epoch 191/200\n",
      "460/460 [==============================] - 0s 462us/step - loss: 0.2648 - accuracy: 0.8848\n",
      "Epoch 192/200\n",
      "460/460 [==============================] - 0s 543us/step - loss: 0.2626 - accuracy: 0.8891\n",
      "Epoch 193/200\n",
      "460/460 [==============================] - 0s 516us/step - loss: 0.2647 - accuracy: 0.8891\n",
      "Epoch 194/200\n",
      "460/460 [==============================] - 0s 447us/step - loss: 0.2620 - accuracy: 0.8913\n",
      "Epoch 195/200\n",
      "460/460 [==============================] - 0s 414us/step - loss: 0.2599 - accuracy: 0.8913\n",
      "Epoch 196/200\n",
      "460/460 [==============================] - 0s 408us/step - loss: 0.2592 - accuracy: 0.8870\n",
      "Epoch 197/200\n",
      "460/460 [==============================] - 0s 395us/step - loss: 0.2590 - accuracy: 0.8804\n",
      "Epoch 198/200\n",
      "460/460 [==============================] - 0s 395us/step - loss: 0.2603 - accuracy: 0.8891\n",
      "Epoch 199/200\n",
      "460/460 [==============================] - 0s 404us/step - loss: 0.2571 - accuracy: 0.8870\n",
      "Epoch 200/200\n",
      "460/460 [==============================] - 0s 397us/step - loss: 0.2555 - accuracy: 0.8870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19579790948>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=200,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/460 [==============================] - 0s 315us/step\n",
      "Accuracy: 90.00\n"
     ]
    }
   ],
   "source": [
    "loss_of_model_on_dataset,accuracy= model.evaluate(X_train,y_train)\n",
    "print('Accuracy: %.2f'%(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24759625015051467\n"
     ]
    }
   ],
   "source": [
    "print(loss_of_model_on_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict_classes(X_test)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda_numpy\\lib\\site-packages\\sklearn\\metrics\\classification.py:635: DeprecationWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  'and multiclass classification tasks.', DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7915309446254072"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "jaccard_similarity_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73  32]\n",
      " [ 32 170]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "print(confusion_matrix(y_test, predictions, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 73  32]\n",
      " [ 32 170]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEVCAYAAABE7SrmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de7xUZb3H8c+Xi1xCBcUrqGghphzlICJ5IVIzNY94UhOzUrM8ml2tU3rsZHbiHLJe3o5amffLUdGyUMtreU0xQFAwUbyjKCDeBYLN7/yx1rZhu/fsmdkze9aa+b59zYuZtZ551m9gOb95LutZigjMzMyypEe9AzAzM2vLycnMzDLHycnMzDLHycnMzDLHycnMzDKnV70DMDOz2uq53lYRq5eX9Z5YvuS2iNivRiF1ysnJzKzBxerl9Bnx2bLes2L2+YNrFE5JnJzMzBqeQPkaxXFyMjNrdAKkekdRFicnM7Nm4JaTmZlljltOZmaWLR5zMjOzLHLLyczMMkW45WRmZlkjt5zMzCyD3HIyM7PMccvJzMyyxbP1zMwsa7xChJmZZZJbTmZmli3569bLV7RmZlaZHirv0QlJl0haLGlum+1flzRf0jxJZxRsP0XSgnTfpzqr3y0nM7NGV5uLcC8DzgOueP8w0ieAicCOEbFS0sbp9u2BScAOwObAnZK2jYiWjip3y8nMrBlI5T06ERH3AsvabD4BmBIRK9Myi9PtE4FrI2JlRDwLLADGFqvfycnMrOGlY07lPCqzLbCnpOmS7pG0S7p9CPBiQbmF6bYOuVvPzMzaM1jSjILXF0bEhZ28pxcwCBgH7AJMlbQNScdiW9FZRWZm1ujKv85paUSMKfM9C4HfRkQAD0taAwxOt29RUG4o8HKxitytZ2bWDLqnW+93wF4AkrYF1gGWAtOASZL6SNoaGA48XKwit5zMzBpdiZMcyqtS1wATSLr/FgKnAZcAl6TTy/8OHJW2ouZJmgo8DqwGTiw2Uw+cnMzMmkOVp5JHxBEd7Pp8B+UnA5NLrd/JycysGXhtPTMzy5b8LV/k5GRm1gzccjIzs0ypzfJFNeXkZGbW8NytZ2ZmWeRuPTMzyxy3nMzMLHPccjIzs0yRx5zMzCyL3HIyM7OskZOTmZlliXByMjOzrBHt3+4vw5yczMwantxyMjOz7HFyMjOzzHFyMjOzzHFyMjOzbPGECDMzyxp5QoSZmWVR3pJTvhZbMusiSf0k3STpTUnXd6GeIyXdXs3Y6kXSnpLm1zsOqy1JZT3qzcnJMknS5yTNkPSOpEWS/ihpjypUfSiwCbBhRBxWaSURcXVE7FuFeGpKUkj6SLEyEXFfRIzorpisPpyczLpI0knA2cB/kySSLYELgIlVqH4r4MmIWF2FunJPkrv2m4EqeNSZk5NliqT1gR8DJ0bEbyPi3YhYFRE3RcS/p2X6SDpb0svp42xJfdJ9EyQtlPQdSYvTVtcx6b7TgR8Ch6ctsmMl/UjSVQXHH5a2Nnqlr4+W9IyktyU9K+nIgu33F7xvN0l/TbsL/yppt4J9d0v6L0kPpPXcLmlwB5+/Nf7vFcR/sKQDJD0paZmk/ygoP1bSg5LeSMueJ2mddN+9abE56ec9vKD+70t6Bbi0dVv6ng+nxxidvt5c0lJJE7r0D2t155aTWdd8DOgL3FikzKnAOGAUsBMwFvhBwf5NgfWBIcCxwPmSBkXEaSStsesiYkBEXFwsEEkfAs4F9o+IdYHdgNntlNsAuCUtuyFwJnCLpA0Lin0OOAbYGFgH+G6RQ29K8ncwhCSZ/hr4PLAzsCfwQ0nbpGVbgG8Dg0n+7vYGvgoQEePTMjuln/e6gvo3IGlFHld44Ih4Gvg+cLWk/sClwGURcXeReC3jWmfrOTmZVW5DYGkn3W5HAj+OiMURsQQ4HfhCwf5V6f5VEfEH4B2g0jGVNcBISf0iYlFEzGunzKeBpyLiyohYHRHXAE8A/1JQ5tKIeDIilgNTSRJrR1YBkyNiFXAtSeI5JyLeTo8/D9gRICJmRsRD6XGfA34FfLyEz3RaRKxM41lLRPwaeAqYDmxG8mPAcs7JyaxrXgMGdzIWsjnwfMHr59Nt79fRJrm9BwwoN5CIeBc4HDgeWCTpFknblRBPa0xDCl6/UkY8r0VES/q8NXm8WrB/eev7JW0r6WZJr0h6i6Rl2G6XYYElEbGikzK/BkYC/xsRKzspa3ngMSezLnkQWAEcXKTMyyRdUq22TLdV4l2gf8HrTQt3RsRtEfFJkhbEEyRf2p3F0xrTSxXGVI5fkMQ1PCLWA/6Dzr9aothOSQNIJqRcDPwo7ba0PJNbTtagJI2QNLvg8Zakb6UD/Y+m226XtHnntXUsIt4kGWc5P50I0F9Sb0n7SzojLXYN8ANJG6UTC34IXNVRnZ2YDYyXtKWSyRintO6QtImkg9Kxp5Uk3YMt7dTxB2BbJdPfe0k6HNgeuLnCmMqxLvAW8E7aqjuhzf5XgW0+8K7izgFmRsSXScbSftnVICX1lfSwpDmS5imZnIKkqyXNlzRX0iWSenf1WNY+JydrSBExPyJGRcQokoH590gmLfwsInZMt99Mkii6eqwzgZNIJjksAV4Evgb8Li3yE2AG8CjwGDAr3VbJse4ArkvrmsnaCaUH8B2SltEykrGcr7ZTx2vAgWnZ14DvAQdGxNJKYirTd0kmW7xN0qq7rs3+HwGXK5nN99nOKpM0EdiPpCsTkn+H0UpnKXbBSmCviNiJZLxtP0njgKuB7YB/AvoBX+7icawD1U5O6Y+JxZLmtrPvu0pmvQ5OX0vSuZIWpD9mR3daf0TRFr7ZB0jal2RAffc2208BtoyItr/ezd6nZBbg/cAJETG9YPu3gcER4QkYVbbORh+JwZ85o/OCBRZdeMjMiBjT0X5J40l6E66IiJEF27cALiL50bFzRCyVdADwdeAAYFeSCT67Fju+W05WiUkkXWsASJos6UWSWXRdbjlZY5LUU9JsYDFwR5vE1JtkxuWt9YrPyhMR95L0KLR1FknvQWHLZyJJEouIeAgYKGmzYvV3a3KSdJmkQ7vzmG2OP1nSi5LeqVcMeafkAs+DgPfXpYuIUyNiC5Iumq/VKzbLtohoSbt/hwJjJY0s2H0BcG9E3Fef6JpAN8zWk3QQ8FJEzGmzawhJ93yrhaw9m/UDctVyktSzi1XcRHLBplVuf2BWRLzazr7/Aw7p5ngsZyLiDeBukrEtJJ0GbEQyvmW1UNlsvcFK1rdsfRxX9BBJd+2ptN970l66KzqmVNPkJOmL6eDXHElXppvHS/qLkiVhDk3LTZB0c8H7zpN0dPr8OUk/VLJUzGFKloL5aTrz50lJe5YaT3qx4qIqfsRmdARrd+kNL9h3EMm0ZrO1pDMrB6bP+wH7AE9I+jLwKeCIiFhTzxgbXQXJaWlEjCl4XNjJIT4MbE2yXNZzJC3kWZI2JWkpbVFQdiidXP5Rs0UfJe1AkkV3TwfENiBZ1mUzYA+SwbJpwA0lVLciIvZI6z0e6BURY9NBttOAfSSN4IMzlVpNSH+tlRr7caTLuvTt13/noVsP7+QdzWHNmjX06NmTrT7y0cOH7zDqEoAPrbs+ffr2A6D/gPXYeLOhDN9hlGfZpNbr63VVAbbb7qM8//xz9OvXn759+zJo0CA222zzPWbNmsk666xDz5493+vfvz8DBw5ks826dDVCQ5k1a+bSiNioGnXVenp4RDxGsjxX6/GeA8ak3//TgK9JupZkQsSbnTUUavl/zl7ADa3TaSNiWfqX87v0F9LjkjYpsa62See36Z8zgWFp/fMpviRMydJfCBcCDN9hVJw7tSFu22N18IkRG3deyKwD/Xqr7cojlatybpJ0DTCBpPtvIckM3o7Wq/wDyUy9BSSXoRzTWf21TE6i/T7FlW3KAKxm7S7Gvm3e824HdbSQfoZqtpzMzBpNtVtOEXFEJ/uHFTwP4MRy6q9lcroLuFHSWRHxmoovgfI8sL2S2x70JVlZ+f4i5T+gmi0nM7NGUuqFtVlSs+QUEfMkTQbukdQCPFKk7IuSppJcpf9UsbJdoWT5m88B/dNm6EUR8aNaHMvMLEucnApExOXA5UX2Dyh4/j2SC7falhnW5vWEgudLScecSoyn3WOYmTU6JyczM8uefOUmJyczs2bglpOZmWWLnJzMzCxjBOQsNzk5mZk1Pk8lNzOzDMpZbnJyMjNrBm45mZlZtsgtJzMzyxgBPXrkKzs5OZmZNQG3nMzMLHM85mRmZtniMSczM8ua5CLcfGUnJyczs4bni3DNzCyDcpabnJzMzJqBW05mZpYtnhBhZmZZ4wkRZmaWSTnLTU5OZmbNwC0nMzPLnJzlJicnM7OG59u0m5lZ1vg27WZmlkFeIcLMzDIoZ7nJycnMrBnkreXUo94BmJmZteXkZGbW6NLli8p5dFqldImkxZLmFmz7maQnJD0q6UZJAwv2nSJpgaT5kj7VWf1OTmZmDa51+aJyHiW4DNivzbY7gJERsSPwJHAKybG3ByYBO6TvuUBSz2KVOzmZmTWBaieniLgXWNZm2+0RsTp9+RAwNH0+Ebg2IlZGxLPAAmBssfqdnMzMmkAF3XqDJc0oeBxX5iG/BPwxfT4EeLFg38J0W4c8W8/MrAlUMFtvaUSMqfBYpwKrgatbN7VTLIrV4eRkZtbouvF+TpKOAg4E9o6I1gS0ENiioNhQ4OVi9bhbz8yswYnyxpsqvSZK0n7A94GDIuK9gl3TgEmS+kjaGhgOPFysLreczMyaQLVbTpKuASaQjE0tBE4jmZ3XB7gjTXAPRcTxETFP0lTgcZLuvhMjoqVY/U5OZmZNoEeVs1NEHNHO5ouLlJ8MTC61ficnM7MmkLPVi5yczMwanXw/JzMzy6Ie+cpNTk5mZs3ALSczM8ucnOUmJyczs0Ynkmud8sTJycysCTTMmJOk9Yq9MSLeqn44ZmZWdV1Y9aFeirWc5pEszFf4iVpfB7BlDeMyM7Mqyllu6jg5RcQWHe0zM7P8ENVfIaLWSlr4VdIkSf+RPh8qaefahmVmZtVU7du011qnyUnSecAngC+km94DflnLoMzMrLq6Y1Xyaipltt5uETFa0iMAEbFM0jo1jsvMzKokK62hcpSSnFZJ6kF610JJGwJrahqVmZlVVSOOOZ0P/AbYSNLpwP3AT2salZmZVZXKfNRbpy2niLhC0kxgn3TTYRExt7ZhmZlZNWVhHKkcpa4Q0RNYRdK151u7m5nlSDKVvN5RlKeU2XqnAtcAmwNDgf+TdEqtAzMzsyopc6ZeFlpZpbScPg/sHBHvAUiaDMwE/qeWgZmZWfVkIN+UpZTk9Hybcr2AZ2oTjpmZ1UIWWkPlKLbw61kkY0zvAfMk3Za+3pdkxp6ZmeVAHsecirWcWmfkzQNuKdj+UO3CMTOzWmiYllNEXNydgZiZWe3kKzWVMOYk6cPAZGB7oG/r9ojYtoZxmZlZlUiNuULEZcClJIl3f2AqcG0NYzIzsypruFXJgf4RcRtARDwdET8gWaXczMxyohGvc1qpJNKnJR0PvARsXNuwzMysmZWSnL4NDAC+QTL2tD7wpVoGZWZm1ZWBxlBZSln4dXr69G3+ccNBMzPLCaHcTYgodhHujaT3cGpPRHymJhGZmVl11WCSg6RLgAOBxRExMt22AXAdMAx4DvhsRLyeDg2dAxxAsrDD0RExq1j9xVpO53U5+gawXt9efGKEh9isMoN2+Vq9QzADanIR7mUkeeKKgm0nA3dFxBRJJ6evv08y03t4+tgV+EX6Z4eKXYR7V5fCNjOzzKj2vY4i4l5Jw9psnghMSJ9fDtxNkpwmAldERAAPSRooabOIWNRR/aXez8nMzHJKVNRyGixpRsHrCyPiwk7es0lrwomIRZJau52GAC8WlFuYbnNyMjNrZhUs/Lo0IsZU6fDtHb3DOQ1QRktPUp+ywzEzs0zoofIeFXpV0mYA6Z+L0+0LgS0Kyg0FXi4ab2dHkjRW0mPAU+nrnST9byVRm5lZ90uWJOqWFSKmAUelz48Cfl+w/YtKjAPeLDbeBKV1651LMl3wdwARMUeSly8yM8uRat/PSdI1JJMfBktaCJwGTAGmSjoWeAE4LC3+B5Jp5AtIppIf01n9pSSnHhHxfJtM2lLqBzAzs/qr9kzyiDiig117t1M2gBPLqb+U5PSipLFASOoJfB14spyDmJlZ/SR3wm2QFSIKnEDStbcl8CpwZ7rNzMxyotrXOdVaKWvrLQYmdUMsZmZWIzlrOJV0J9xf08589Ig4riYRmZlZVUkNtPBrgTsLnvcF/pW1r/Q1M7OMy1luKqlb77rC15KuBO6oWURmZlZ11Z5KXmuVLF+0NbBVtQMxM7PaaMjZepJe5x9jTj2AZSTLoJuZWU7kLDcVT07pDaJ2Al5KN61JL6YyM7O86Np6eXVRdOp7mohujIiW9OHEZGaWQyrzv3or5bqshyWNrnkkZmZWE8mYU7esSl41HXbrSeoVEauBPYCvSHoaeJfkc0ZEOGGZmeVEFhJOOYqNOT0MjAYO7qZYzMysRrpwG4y6KJacBBART3dTLGZmVgOt3Xp5Uiw5bSTppI52RsSZNYjHzMyqTY01lbwnMID27/1uZmY50kgX4S6KiB93WyRmZlYTjdatl7OPYmZmHclZw6locvrArXbNzCyPRI+ctTc6TE4Rsaw7AzEzs9oQjdVyMjOzRpCRVR/K4eRkZtYEGmm2npmZNQB365mZWSblreVUyqrkZmZm3cotJzOzJpCzhpOTk5lZoxP56yZzcjIza3RqrFtmmJlZg8hXaspfS8/MzMqULPyqsh6d1il9W9I8SXMlXSOpr6StJU2X9JSk6yStU2nMTk5mZk1AZT6K1iUNAb4BjImIkSS3WJoE/BQ4KyKGA68Dx1Yar5OTmVkTkMp7lKAX0E9SL6A/sAjYC7gh3X85cHCl8To5mZk1PCGV9wAGS5pR8DiutbaIeAn4OfACSVJ6E5gJvBERq9NiC4EhlUbsCRFmZg2uwqnkSyNiTLv1SYOAicDWwBvA9cD+7RSN8g+bcHIyM2sCVZ5Kvg/wbEQsSev+LbAbMFBSr7T1NBR4udIDuFvPzKwJVHNCBEl33jhJ/ZVkvb2Bx4E/A4emZY4Cfl9pvE5OZmaNLr0It8wxpw5FxHSSiQ+zgMdIcsmFwPeBkyQtADYELq40ZHfrmZk1uFosXxQRpwGntdn8DDC2GvU7OZmZNQEvX2RmZpmTr9Tk5GRm1hRy1nBycjIza3TJmFO+spOTk5lZE3DLyczMMkbILSczM8sat5zMzCxTPOZkZmbZU/ptMDLDycnMrAk4OZmZWeZ4QoSZmWWKgB75yk1OTmZmzcAtJzMzyxyPOZmZWea45WRmZpniMSczM8sgL19kZmZZ44twzcwsi3KWm5ycrDQrVqxgn0+M5+8rV7K6ZTX/+plD+c/TTufoLxzJrFkz6N27N2PGjOW8X/yK3r171ztcy4BfnnYk+48fyZJlbzPmsP8G4MopxzB82CYADFy3H2+8vZxxk6YA8N0v7cvREz9Gy5o1fOeMG7jzwb/VLfZGk4w55Ss99ah3AJYPffr04dY7/sTDs+YwfcZsbr/tVqY/9BCTPnckc+Y+wYxHHmP5iuVcevFF9Q7VMuLKmx5i4onnr7XtCydfyrhJUxg3aQq/u2s2v//TbAC222ZTDvvUaEYfOpmDTryAc075LD3yNoKfcSrzUW9OTlYSSQwYMACAVatWsXrVKiSx3/4HIAlJjBkzlpdeWljnSC0rHpj1NMvefK/D/Yd8cjRTb50JwIETduT622bx91Wref7l13j6xaXsMnJYN0XaJHKWnZycrGQtLS3suvMottx8Y/ba55OM3XXX9/etWrWKa66+kk9+ar86Rmh5sfvoD/Pqsrd5+oUlAAzZaH0WvvL6+/tfWvw6m2+8fr3Cswzo1uQk6TJJh3bnMdscf2dJj0laIOlcKWedsHXWs2dPps+czYLnFjLjrw8zb+7c9/d982tfZfc9x7PHHnvWMULLi8/uN4brb53xjw3t/K8Y0Y0BNQGV+V+95arlJKlnF6v4BXAcMDx9+Gd+BQYOHMj4j0/g9ttvBWDyf53OkqVLOOPnZ9Y5MsuDnj17MHGvnbjhtlnvb3tp8RsM3XTQ+6+HbDyIRUverEd4DUsq71FvNU1Okr4o6VFJcyRdmW4eL+kvkp5pbUVJmiDp5oL3nSfp6PT5c5J+KOl+4DBJd0v6qaSHJT0pqaSf6pI2A9aLiAcjIoArgIOr+Xkb2ZIlS3jjjTcAWL58OX+6605GjNiOSy++iDtuv40rrrqGHj1y9VvH6mSvXUfw5HOv8tLiN97fdsvdj3LYp0azTu9ebLX5hnxky43469zn6hdkA8rZkFPtppJL2gE4Fdg9IpZK2gA4E9gM2APYDpgG3FBCdSsiYo+03uOBXhExVtIBwGnAPpJGANd18P4JwBCgcLR+YbqtvdiPI2lhAbzTr7fmlxBjo+sHbJ0+F7DsLw/cvwjYGVi5wXr916T7XgcW1SE+y5hp06ZtPW7cuHUHDRrU67lb/3P1lClTXj777LOXHvWDG4bddN2v310x+/wlwGBg6SOz4Y9je2869zffGdzS0sL3TvrqC+/Nuv6ten+GDNiqajVlIeOUoZbXOe0F3BARSwEiYlk6xPO7iFgDPC5pkxLrapt0fpv+ORMYltY/HxjVUQUdjC+126sdERcCF5YYW1OTNCMixtQ7Dsu2TTbZhLPOOouzzjoLgEMOOYQzzjijw/Nn6tSp3R5jI0taQ/nKTrVMTqL9L/+VbcoArGbtLsa+bd7zbgd1tJB+hhJaTguBoQXbhgIvd1DezKxxZGQcqRy1HCS4C/ispA0B0m69jjwPbC+pj6T1gb3LPVhEzI+IUR083oiIRcDbksalragvAr+v4HOZmeVOLcacJA2UdIOkJyT9TdLHJG0g6Q5JT6V/Duq8pg+qWXKKiHnAZOAeSXNIxps6KvsiMBV4FLgaeKRGYZ0AXAQsAJ4G/lij4zQTd39aV/j86S61mRFxDnBrRGwH7AT8DTgZuCsihpM0Uk6uKNzwxQRmZg1t+x1Hx9U33VPWe0YPW29msfFkSesBc4BtoiCRSJoPTIiIReks6bsjYkS5MXvur5lZE6jgOqfBkmYUPI5rU+U2wBLgUkmPSLpI0oeATdJhFNI/N64kXq9KbmbW4Cq8dmlpJzNxewGjga9HxHRJ51BhF1573HIys0xrvQzEy411UfXHnBYCCyNievr6BpJk9Wrande6+MHiSsJ1crJuUYWlp6x59QdoHddwkqpMtdfWi4hXgBfTy3ggmWX9OMniCkel246iwlnR7tazmpI0HlgUEU9J6hkRLfWOyfJD0v7A0ZIWALOAmyNipSSFZ3OVpUYp/evA1ZLWAZ4BjiFp9EyVdCzwAnBYJRU7OVnNSNoHuB1YIWlcRDzqBGWlkjQKuBQ4FhhJsuzZvpK+FRHLnaDKU4vcFBGzgfbGpcq+VrUtd+tZTaS/pPYkWfn9RODPknaMiBZJ/lFkpRBwbUTcApwN/ApYAZwpqY8TUxnKHW/KQMepk5PVRET8HTgfeCQiLgV+TJKgRkXEavDYgXVqOTBR0r4RsRJ4EvglyfJle4PPoXLk7X5O/gVrNRMRi1u/PCLinPT5XZI+CnwU2AK4qp4xWjZJ6hERT0g6BThZ0vKIuE/S08BbJKvh/8Gtp9KI/K2t5+RkVdc6riSpV0SsltSDZLLV2ZKWAq8Ar5IsyGu2ljbnz7XpSgQ/kTQlIv4oaRGwS9p1vMoJqjQ5y01OTlZdBV8sWwH/K+nzEfFWOs60GliaPvZOb3Ni9r4258+5ko4kmRTxJnCepLuATwP7pl3HVqqcZScnJ6uagi+WoSQL+J4PrC9p44hYIGldYHdgr4h4vK7BWua0c/5cAAwC+kbEdZIeBnoDP46IhcXqsg/KwjhSOTwhwqqizRfL9SSr0D8E3EN6B92IeBs4PSLm1i9Sy6IOzp8HWfv8eTYinnRiqkwFa+vVlZOTVUX6xbIlyV2KzyC57cn1wDci4o6CiRGr6ximZVQn58/tnpXXdTmbSe5uPatMBxdAfpHkF+8ckrsSnx4RN8M/lp4xA58/dZGFjFMGJycrW+EXSzotfGVEPBMRP5G0KXAv8N2IuKmugVom+fzpfklrKF/ZycnJytLmi+VbJKs/zJW0LCKOJZmJd0REzKxnnJZNPn/qJCPjSOXwmJOVpeCLZRzJbZk/AXwFGCLpqohYHREzvUSRtcfnT/3kbczJycnKln6xXAAMAN6KiKXAocAGkqaBJz5Yx3z+1EnOspOTk3WqcKZUugz+SODnJLdfHp8uwvkOcDiwWtLm9YnUssjnTxaUu7Je/bOTm87WqYKumH2B7YEzI+Kl9DvnJKCHpNsj4m1Jh3hmlRXy+ZMNeRtzcnKyDrUZvP4QyYrQrwJnpAtz/p+kFuBHJEsTeSFOe5/Pn+zISE9dWdytZx0q+GIZA/QFxgN9gGMiYk1a5jpgMjCvXnFaNvn8yZicjTm55WQf0PqLN11NfDDJrZifI7nh22eAW9IiPwWIiN/ULVjLHJ8/2ZSFcaRyuOVkH1DQtaKIWEwys2pD4GvA6ySrQn9L0rfrFKJlmM+fbPLaetYQJI0HrpDULyKmA5cDw4BTgSXArsC0+kVoWebzJ3ty1qvn5GSJdhbWXAysAM6S1D8i/kqyEOck4N+AhRHxdDeHaRnl88eqzcnJkNS3YPD6nyXtGBFPkMyiCuDctOhK4AHgmtYBbTOfPzlQZpdeFrr1PCGiyUn6J2CcpKuALwHfBF6R9GpEHCbpv4CfS5pJcqO3wyNiUR1Dtgzx+ZMnGcg4ZXBysq2A/YH+wMeAsRHxhqTpkq6PiMOAz0naDXjWXyzWhs+fHBDZaA2Vw916TSqd5kt6v5wHSBbhHEQy9ZeI2JVkMc4/pa//4i8Wa+XzJ388IcJyobXPX9LxwGjgTuAtYE9JW6RldgPWpLfONnufz5/88ZiT5Yakg0jup/PpiHhB0lski29K0p8j4tmI2Ke+UVpW+fzJl7xdhOvk1Nw2J5k59YKkXhFxc7rW2ZeA5ZJeBFq83k1sZf0AAAT3SURBVJl1wOdPnuQrN7lbr8k9T9INM6Lg/jk9gNeAP6c3fvMXi3XE50+O5G3MyS2n5vYAsDtwlKS/AAOBbwCTIuKVukZmeeDzJydqNY4kqScwA3gpIg6UtDVwLbABMAv4QkT8vZK63XJqYhHxFnA+8ALwVZI1z74cEc/UNTDLBZ8/+VKjmw1+E/hbweufAmdFxHCSdRSPrTReJ6cmFxGLIuKXwMHAURHxaL1jsvzw+ZMjVe7XS2dhfhq4KH0tYC/ghrTI5STnRUXcrWcAVNr0NgOfP3lQg169s4HvAeumrzcE3igYf1wIDKm0creczMyaQAXXOQ2WNKPgcdw/6tKBwOKImFl4iHYOW/GEGLeczMwaXlnjSK2WRsSYDvbtDhwk6QCSuxyvR9KSGpheVrAaGAq8XGnEbjmZmTW41rX1qrVCREScEhFDI2IYyW1Q/hQRRwJ/Bg5Nix0F/L7SmJ2czMysWr4PnCRpAckY1MWVVuRuPTOzJlCr9fIi4m7g7vT5M8DYatTrlpM1DEktkmZLmivpekn9u1DXBEk3p88PknRykbIDJX21gmP8SNJ3S93epsxlkg4tVqZN+WGS5pYbozWOGl3nVDNOTtZIlkfEqIgYCfwdOL5wpxJln/MRMS0iphQpMpDkIlSzbMrhnXCdnKxR3Qd8JG0x/E3SBSTLqWwhaV9JD0qalbawBgBI2k/SE5LuBz7TWpGkoyWdlz7fRNKNkuakj92AKcCH01bbz9Jy/y7pr5IelXR6QV2nSpov6U5gRGcfQtJX0nrmSPpNm9bgPpLuk/RkOrUXST0l/azg2P/W1b9Iy79yr7/NQG5ycrLGI6kXyd1ZH0s3jQCuiIh/Bt4FfgDsExGjSdYFO0lSX+DXwL8AewKbdlD9ucA9EbETyX2M5gEnA0+nrbZ/l7QvMJyk730UsLOk8ZJ2JpnZ9M8kyW+XEj7ObyNil/R4f2Pt5WCGAR8nuUr/l+lnOBZ4MyJ2Sev/SrremTW7nGUnT4iwRtJP0uz0+X0kM4U2B56PiIfS7eOA7YEHktVWWAd4ENiO5DbiTwFIugo4jg/aC/giQES0AG9KGtSmzL7p45H09QCSZLUucGNEvJceY1oJn2mkpJ+QdB0OAG4r2Dc1venfU5KeST/DvsCOBeNR66fHfrKEY1kDy8I4UjmcnKyRLI+IUYUb0gT0buEm4I6IOKJNuVF04Wr2NgT8T0T8qs0xvlXBMS4DDo6IOZKOBiYU7GtbV6TH/npEFCYxJA0r87jWYLIwjlQOd+tZs3kI2F3SRwAk9Ze0LfAEsLWkD6fljujg/XcBJ6Tv7SlpPeBt/rG+GCStmy8VjGUNkbQxcC/wr5L6SVqXpAuxM+sCiyT1Bo5ss+8wST3SmLcB5qfHPiEtj6RtJX2ohONYg8tZr55bTtZcImJJ2gK5RlKfdPMPIuLJdO2wWyQtBe4HRrZTxTeBCyUdC7QAJ0TEg5IeSKdq/zEdd/oo8GDacnsH+HxEzJJ0HTCb5EZ995UQ8n8C09Pyj7F2EpwP3ANsAhwfESskXUQyFjUrXSV6CV1YGdoaSBYyThnkG1WamTW20TuPiQcemlHWe/qvo5lF1tarObeczMwaXOvaennilpOZWYOTdCswuMy3LY2I/WoRTymcnMzMLHM8W8/MzDLHycnMzDLHycnMzDLHycnMzDLHycnMzDLn/wHvpvWU8wwxDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, predictions, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       202\n",
      "           1       0.70      0.70      0.70       105\n",
      "\n",
      "    accuracy                           0.79       307\n",
      "   macro avg       0.77      0.77      0.77       307\n",
      "weighted avg       0.79      0.79      0.79       307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6502232836492527"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "predictions_prob = model.predict_proba(X_test)\n",
    "log_loss(y_test, predictions_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6405353265637751, -0.7152971682859277, -0.573567244000577, 0.7829069725890075, 0.9556328374764441, 0.25488727331523364, -0.12579662422835297, 0.8328030107997808] => 0 (expected 0)\n",
      "[-0.8437262911837038, 1.1308981637418536, 0.1497404560673259, 0.030256484213278943, 0.7646737580915557, -0.8105689808308659, -1.0525018335396417, -0.7849573566202676] => 0 (expected 0)\n",
      "[-0.546873967634208, -0.4023827052303715, -0.2635782296857615, -1.2868818704442462, -0.6935592117566833, -0.15100082350232807, -0.9468514025106674, -1.0403932041076436] => 0 (expected 0)\n",
      "[1.2342399736627667, -0.43367415153592714, 0.5630591418204133, -1.2868818704442462, -0.6935592117566833, -0.937409011086354, 1.1601200505814484, 0.06649546833765263] => 1 (expected 0)\n",
      "[0.6405353265637751, -0.21463402739703785, -3.5701277157104605, -1.2868818704442462, -0.6935592117566833, -4.05767375537136, -0.8532753064564332, -0.6146667916286835] => 0 (expected 0)\n",
      "[0.34368300301427934, -0.3085083663137047, 0.1497404560673259, 0.469302602432454, -0.6935592117566833, -1.026197032265196, -0.1952240503331074, -0.5295215091328915] => 0 (expected 0)\n",
      "[0.6405353265637751, -0.8717543998137057, -0.9868859297536644, 0.5947443504950753, -0.1380418899097351, -0.4173648870388532, -0.34917182126104135, -0.8701026391160596] => 0 (expected 0)\n",
      "[0.34368300301427934, -0.18334258109148222, 0.3563997989438696, -1.2868818704442462, -0.6935592117566833, -0.10026481140013303, -0.3884134099289463, 0.9179482932955728] => 1 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print('%s => %d (expected %d)' % (X_test[i].tolist(), predictions[i], y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diabetes_prediction.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(model, filename=\"diabetes_prediction.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
